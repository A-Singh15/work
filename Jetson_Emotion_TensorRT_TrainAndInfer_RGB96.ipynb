{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24ba45c",
   "metadata": {},
   "source": [
    "# ðŸš€ Jetson Emotion Detection: Train + TensorRT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e3ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75b42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONFIG ===\n",
    "image_size = (96, 96)\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5163c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_labels = list(train_generator.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3a0897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 94, 94, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 47, 47, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 45, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 22, 22, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 10, 10, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6553856   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6926471 (26.42 MB)\n",
      "Trainable params: 6926471 (26.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), activation='relu', input_shape=(96, 96, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed136fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m     train_generator,\n\u001b[1;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      6\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_generator,\n\u001b[1;32m      7\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop]\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === SAVE FOR TensorRT ===\n",
    "os.makedirs(\"saved_model\", exist_ok=True)\n",
    "model.save(\"saved_model\")\n",
    "print(\"âœ… Model saved to 'saved_model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75538360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONVERT TO TENSORRT ===\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=\"saved_model\")\n",
    "converter.convert()\n",
    "converter.save(\"trt_model\")\n",
    "print(\"âœ… TensorRT optimized model saved to 'trt_model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === RUN TENSORRT INFERENCE ===\n",
    "import tensorflow as tf\n",
    "\n",
    "image_dir = \"images\"\n",
    "infer_model = tf.saved_model.load(\"trt_model\")\n",
    "infer_fn = infer_model.signatures['serving_default']\n",
    "\n",
    "for img_file in os.listdir(image_dir)[:5]:\n",
    "    path = os.path.join(image_dir, img_file)\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    norm = img.astype(\"float32\") / 255.0\n",
    "    norm = np.expand_dims(norm, axis=0)  # Shape: (1, 48, 48, 1)\n",
    "    tensor_input = tf.convert_to_tensor(norm)\n",
    "\n",
    "    result = infer_fn(tensor_input)\n",
    "    preds = list(result.values())[0].numpy()[0]\n",
    "    label = class_labels[np.argmax(preds)]\n",
    "    conf = np.max(preds)\n",
    "\n",
    "    print(f\"{img_file} â†’ {label} ({conf*100:.2f}%)\")\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"{label} ({conf*100:.2f}%)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
