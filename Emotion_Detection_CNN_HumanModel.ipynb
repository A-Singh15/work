{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257165d0",
   "metadata": {},
   "source": [
    "# ü§ñ Emotion Detection (Your CNN + Human Model)\n",
    "Test your own trained CNN vs a lightweight model from human-models-main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aaf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2191182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CONFIGURATION ===\n",
    "image_size = (48, 48)\n",
    "image_folder = \"images\"\n",
    "EMOTIONS = [\"angry\", \"disgusted\", \"fearful\", \"happy\", \"neutral\", \"sad\", \"surprised\"]\n",
    "\n",
    "# === LOAD KERAS MODEL ===\n",
    "def load_keras_model(json_path, weights_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        model = model_from_json(f.read())\n",
    "    model.load_weights(weights_path)\n",
    "    return model\n",
    "\n",
    "model_keras = load_keras_model(\"models/emotion_model.json\", \"models/emotion_model_weights.h5\")\n",
    "print(\"‚úÖ Keras model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5987612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === LOAD HUMAN MODEL (JSON + BIN) ===\n",
    "def load_human_model(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        model_json = json.load(f)\n",
    "    return model_json\n",
    "\n",
    "# Only loading the json structure here\n",
    "human_model_json = load_human_model(\"/mnt/data/human-models-main/models/emotion.json\")\n",
    "print(\"‚úÖ Human model (metadata) loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d700697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === PREDICT USING KERAS MODEL ===\n",
    "def predict_emotions_keras(folder):\n",
    "    for img_file in os.listdir(folder):\n",
    "        if not img_file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(folder, img_file)\n",
    "        img = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, image_size)\n",
    "\n",
    "        face_img = resized.astype(\"float32\") / 255.0\n",
    "        face_img = np.expand_dims(img_to_array(face_img), axis=0)\n",
    "\n",
    "        preds = model_keras.predict(face_img)[0]\n",
    "        label = EMOTIONS[np.argmax(preds)]\n",
    "        confidence = np.max(preds)\n",
    "\n",
    "        print(f\"[Keras] {img_file} ‚Üí {label} ({confidence*100:.2f}%)\")\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Keras: {label} ({confidence*100:.2f}%)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === PREDICT USING HUMAN MODEL (Placeholder for now) ===\n",
    "def predict_emotions_webmodel(folder):\n",
    "    print(\"‚ö†Ô∏è Web/ONNX model placeholder ‚Äî add ONNX or JS inference backend if needed.\")\n",
    "    print(\"Model info:\", human_model_json.get(\"name\", \"N/A\"), \"| format:\", human_model_json.get(\"format\", \"N/A\"))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
